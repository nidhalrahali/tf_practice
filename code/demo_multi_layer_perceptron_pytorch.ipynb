{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PyTorch version:[1.3.1].\nThis notebook use [cpu].\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format='retina'\n",
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"This notebook use [%s].\"%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ready.\n"
    }
   ],
   "source": [
    "def truncated_normal(size, threshold=1, dtype=torch.float, requires_grad=True):\n",
    "    values = truncnorm.rvs(-threshold, threshold, size=size)\n",
    "    values = torch.from_numpy(values).type(dtype)\n",
    "    values.requires_grad = requires_grad\n",
    "    return values\n",
    "\n",
    "class mlp(nn.Module):\n",
    "    def __init__(self, in_features=784, h_dims=[256, 256], \n",
    "                    actv=nn.ReLU, out_actv=nn.ReLU, USE_DROPOUT=False):\n",
    "        \"\"\"\n",
    "        Multi-layer perceptron \n",
    "        \"\"\"\n",
    "        super(mlp, self).__init__()\n",
    "\n",
    "        layers = []\n",
    "        in_features = in_features\n",
    "        for h_dim in h_dims[:-1]:\n",
    "\n",
    "            linear = nn.Linear(in_features, h_dim)\n",
    "            # ki = truncated_normal(size=(h_dim, in_features), dtype=torch.float, requires_grad=True)\n",
    "            # linear.weight = nn.Parameter(ki)\n",
    "            layers.append(linear)\n",
    "            \n",
    "            act = actv(inplace=True)\n",
    "            layers.append(act)\n",
    "\n",
    "            in_features = h_dim\n",
    "            \n",
    "            if USE_DROPOUT:\n",
    "                layers.append(nn.Dropout())\n",
    "        linear = nn.Linear(in_features, h_dims[-1])     \n",
    "        # ki = truncated_normal(size=(h_dims[-1], in_features), dtype=torch.float, requires_grad=True)\n",
    "        # linear.weight = nn.Parameter(ki)\n",
    "        layers.append(linear)\n",
    "        \n",
    "        if out_actv:\n",
    "            act = out_actv(inplace=True)\n",
    "            layers.append(act)\n",
    "        \n",
    "        self.moedl = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.moedl(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST('../data/mnist_data/',\n",
    "                             download=True,\n",
    "                             train=True) \n",
    "x_train = train_dataset.data.unsqueeze(1)/255.\n",
    "x_train = torch.flatten(x_train, 1)\n",
    "y_train = train_dataset.targets\n",
    "n_train = train_dataset.data.shape[0]\n",
    "\n",
    "test_dataset = datasets.MNIST(\"../data/mnist_data/\", \n",
    "                             download=True,\n",
    "                             train=False)\n",
    "\n",
    "x_test = test_dataset.data.unsqueeze(1)/255.\n",
    "x_test = torch.flatten(x_test, 1)\n",
    "y_test = test_dataset.targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ready.\n"
    }
   ],
   "source": [
    "class MultiLayerPerceptronClsClass(object):\n",
    "    \"\"\"\n",
    "    MLP for classification\n",
    "    \"\"\"\n",
    "    def __init__(self, name='mlp', x_dim=784, y_dim=10, h_dims=[128,128], actv=nn.ReLU):\n",
    "        \"\"\"\n",
    "        Initialize\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.x_dim = x_dim\n",
    "        self.y_dim = y_dim\n",
    "        self.h_dims = h_dims\n",
    "        self.actv = actv\n",
    "        self.build_model()\n",
    "        self.main_vars = sum([parameter.numel() for parameter in self.net.parameters()])\n",
    "        print(\"[%s] instantiated.\"%(self.name))\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Build model\n",
    "        \"\"\"\n",
    "        self.net = mlp(in_features=self.x_dim, h_dims=self.h_dims+[self.y_dim],\n",
    "                         actv=self.actv, out_actv=None)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.optim = optim.Adam(self.net.parameters(), lr=0.001)\n",
    "    \n",
    "    def update(self, x_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Update model \n",
    "        \"\"\"\n",
    "        y_pred = self.net(x_batch)\n",
    "        cost_val = self.loss(y_pred, y_batch)\n",
    "        self.optim.zero_grad()\n",
    "        cost_val.backward()\n",
    "        self.optim.step()\n",
    "        return cost_val\n",
    "    \n",
    "    def test(self, test_x, test_y, batch_size):\n",
    "        \"\"\"\n",
    "        Test the model\n",
    "        \"\"\"\n",
    "        n_test = len(x_test)\n",
    "        p_idx = np.random.permutation(n_test)\n",
    "        max_iter = np.ceil(n_test/batch_size).astype(np.int) # number of iterations\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for it in range(max_iter):\n",
    "                b_idx = p_idx[batch_size*(it):batch_size*(it+1)]\n",
    "                x_batch, y_batch = test_x[b_idx].to(device), test_y[b_idx].to(device)\n",
    "                y_pred = self.net(x_batch)\n",
    "                _, predicted = torch.max(y_pred.data, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "            val_acc = (100 * correct / total)\n",
    "        return val_acc\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[mlp] instantiated.\n"
    }
   ],
   "source": [
    "M = MultiLayerPerceptronClsClass()\n",
    "M.net = M.net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 moedl.0.weight torch.Size([128, 784])\n1 moedl.0.bias torch.Size([128])\n2 moedl.2.weight torch.Size([128, 128])\n3 moedl.2.bias torch.Size([128])\n4 moedl.4.weight torch.Size([10, 128])\n5 moedl.4.bias torch.Size([10])\n"
    }
   ],
   "source": [
    "for v_idx,(name, var) in enumerate(M.net.named_parameters()):\n",
    "    print (v_idx, name, var.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch:[1/20] cost:[119.244] test_accuracy:[80.330]\nepoch:[2/20] cost:[26.327] test_accuracy:[85.920]\nepoch:[3/20] cost:[17.132] test_accuracy:[88.060]\nepoch:[4/20] cost:[12.645] test_accuracy:[89.360]\nepoch:[5/20] cost:[9.816] test_accuracy:[90.490]\nepoch:[6/20] cost:[7.815] test_accuracy:[90.900]\nepoch:[7/20] cost:[6.324] test_accuracy:[91.140]\nepoch:[8/20] cost:[5.239] test_accuracy:[92.100]\nepoch:[9/20] cost:[4.349] test_accuracy:[92.320]\nepoch:[10/20] cost:[3.611] test_accuracy:[92.700]\nepoch:[11/20] cost:[3.036] test_accuracy:[92.640]\nepoch:[12/20] cost:[2.537] test_accuracy:[92.820]\nepoch:[13/20] cost:[2.131] test_accuracy:[93.240]\nepoch:[14/20] cost:[1.788] test_accuracy:[93.210]\nepoch:[15/20] cost:[1.530] test_accuracy:[93.440]\nepoch:[16/20] cost:[1.298] test_accuracy:[93.490]\nepoch:[17/20] cost:[1.075] test_accuracy:[93.810]\nepoch:[18/20] cost:[0.925] test_accuracy:[93.640]\nepoch:[19/20] cost:[0.758] test_accuracy:[93.540]\nepoch:[20/20] cost:[0.636] test_accuracy:[93.620]\nDone.\n"
    }
   ],
   "source": [
    "max_epoch,batch_size,print_every = 20,128,1\n",
    "\n",
    "max_iter = np.ceil(n_train/batch_size).astype(np.int) # number of iterations\n",
    "for epoch in range(max_epoch):\n",
    "    p_idx = np.random.permutation(n_train)\n",
    "    cost_val_sum,cnt = 0,0\n",
    "    for it in range(max_iter):\n",
    "        b_idx = p_idx[batch_size*(it):batch_size*(it+1)]\n",
    "        x_batch,y_batch = x_train[b_idx].to(device), y_train[b_idx].to(device)\n",
    "        cost_val = M.update(x_batch=x_batch,y_batch=y_batch)\n",
    "        cost_val_sum += cost_val*len(b_idx)\n",
    "        cnt += len(b_idx)\n",
    "    cost_val_avg = cost_val_sum / cnt\n",
    "    if ((epoch%print_every)==0) or (epoch==(max_epoch-1)):\n",
    "        accr_val = M.test(x_test, y_test, batch_size)\n",
    "        print (\"epoch:[%d/%d] cost:[%.3f] test_accuracy:[%.3f]\"%\n",
    "               (epoch+1,max_epoch,cost_val_avg,accr_val))\n",
    "print (\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python_defaultSpec_1601478072140",
   "display_name": "Python 3.7.9 64-bit ('tc': conda)",
   "metadata": {
    "interpreter": {
     "hash": "15ecdb9b5e83d2b99a1cababf200bb9c67cba8876c99aabf076a7fd995d5ced5"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}