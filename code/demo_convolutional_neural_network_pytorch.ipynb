{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PyTorch version:[1.6.0].\nThis notebook use [cuda:0].\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from util_pytorch import mlp\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format='retina'\n",
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"This notebook use [%s].\"%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "n_train:[60000], n_test:[10000], x_dim:[torch.Size([1, 28, 28])], y_dim:[torch.Size([60000])]\n"
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST('../data/mnist_data/',\n",
    "                             download=True,\n",
    "                             train=True) \n",
    "x_train = train_dataset.data.unsqueeze(1)/255.\n",
    "y_train = train_dataset.targets\n",
    "n_train = len(x_train)\n",
    "\n",
    "test_dataset = datasets.MNIST(\"../data/mnist_data/\", \n",
    "                             download=True,\n",
    "                             train=False)\n",
    "\n",
    "x_test = test_dataset.data.unsqueeze(1)/255.\n",
    "y_test = test_dataset.targets\n",
    "n_test = len(x_test)\n",
    "print (\"n_train:[%d], n_test:[%d], x_dim:[%s], y_dim:[%s]\"%\n",
    "       (n_train,n_test,x_train.shape[1:],y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Ready.\n"
    }
   ],
   "source": [
    "class ConvNetClsClass(object):\n",
    "    \"\"\"\n",
    "    CNN for classification\n",
    "    \"\"\"\n",
    "    def __init__(self,name='CNN',img_dim=[1,28,28], y_dim=10,\n",
    "                 filter_sizes=[32,32],kernel_sizes=[3,3],h_dims=[128],\n",
    "                 USE_BN=True, USE_DROPOUT=True, device=None):\n",
    "        self.name = name\n",
    "        self.y_dim = y_dim\n",
    "        self.img_dim = img_dim\n",
    "        self.downsample_ratio = len(filter_sizes)*2\n",
    "        \n",
    "        self.filter_sizes = filter_sizes\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.h_dims = h_dims\n",
    "        \n",
    "        self.USE_BN = USE_BN\n",
    "        self.USE_DROPOUT = USE_DROPOUT\n",
    "        \n",
    "        self.device = device\n",
    "        self.build_model()\n",
    "        self.main_vars = sum([parameter.numel() for parameter in self.net.parameters()])\n",
    "        print(\"[%s] instantiated.\"%(self.name))\n",
    "        \n",
    "    def build_model(self):\n",
    "        \"\"\"\n",
    "        Build model\n",
    "        \"\"\"\n",
    "        # Conv layers\n",
    "        in_features = self.img_dim[0]\n",
    "        layer_list = []\n",
    "        for (filter_size,kernel_size) in zip(self.filter_sizes,self.kernel_sizes):\n",
    "            layer_list.append(nn.Conv2d(in_features, filter_size, kernel_size=3, stride=1, padding=1))\n",
    "            layer_list.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            if self.USE_BN:\n",
    "                layer_list.append(nn.BatchNorm2d(filter_size))\n",
    "            layer_list.append(nn.ReLU(inplace=True))\n",
    "            in_features = filter_size\n",
    "        conv_block = nn.Sequential(*layer_list)\n",
    "        \n",
    "        # Dense layers\n",
    "        layer_list = []\n",
    "        layer_list.append(nn.Flatten())\n",
    "        in_features = (self.img_dim[1]//self.downsample_ratio) * (self.img_dim[2]//self.downsample_ratio) * in_features\n",
    "        layer_list.append(mlp(in_features,h_dims=self.h_dims+[self.y_dim],actv=nn.ReLU,out_actv=None,\n",
    "                                      USE_DROPOUT=True))\n",
    "        dense = nn.Sequential(*layer_list)\n",
    "        \n",
    "        self.net = nn.Sequential(*[conv_block, dense]).to(self.device)\n",
    "        self.cost = nn.CrossEntropyLoss()\n",
    "        self.optim = optim.Adam(self.net.parameters(), lr=0.001)\n",
    "        \n",
    "        \n",
    "    def update(self, x_batch, y_batch):\n",
    "        \"\"\"\n",
    "        Update model \n",
    "        \"\"\"\n",
    "        y_pred = self.net(x_batch)\n",
    "        cost_val = self.cost(y_pred, y_batch)\n",
    "        self.optim.zero_grad()\n",
    "        cost_val.backward()\n",
    "        self.optim.step()\n",
    "        return cost_val\n",
    "    \n",
    "    def get_accr(self, x, y, batch_size):\n",
    "        \"\"\"\n",
    "        Test the model\n",
    "        \"\"\"\n",
    "        n_test = len(x_test)\n",
    "        p_idx = np.random.permutation(n_test)\n",
    "        max_iter = np.ceil(n_test/batch_size).astype(np.int) # number of iterations\n",
    "        with torch.no_grad():\n",
    "            test_loss = 0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for it in range(max_iter):\n",
    "                b_idx = p_idx[batch_size*(it):batch_size*(it+1)]\n",
    "                x_batch, y_batch = x[b_idx].to(self.device), y[b_idx].to(self.device)\n",
    "                y_pred = self.net(x_batch)\n",
    "                _, predicted = torch.max(y_pred.data, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "            acc = (100 * correct / total)\n",
    "        return acc\n",
    "        \n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[CNN] instantiated.\n"
    }
   ],
   "source": [
    "C = ConvNetClsClass(name='CNN',y_dim=10,img_dim=[1,28,28],\n",
    "                    filter_sizes=[32,32],kernel_sizes=[3,3],h_dims=[128],\n",
    "                    USE_BN=True,USE_DROPOUT=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 0.0.weight torch.Size([32, 1, 3, 3])\n1 0.0.bias torch.Size([32])\n2 0.2.weight torch.Size([32])\n3 0.2.bias torch.Size([32])\n4 0.4.weight torch.Size([32, 32, 3, 3])\n5 0.4.bias torch.Size([32])\n6 0.6.weight torch.Size([32])\n7 0.6.bias torch.Size([32])\n8 1.1.moedl.0.weight torch.Size([128, 1568])\n9 1.1.moedl.0.bias torch.Size([128])\n10 1.1.moedl.3.weight torch.Size([10, 128])\n11 1.1.moedl.3.bias torch.Size([10])\n"
    }
   ],
   "source": [
    "for v_idx,(name, var) in enumerate(C.net.named_parameters()):\n",
    "    print (v_idx, name, var.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "epoch:[1/20] cost:[0.164] test_accuracy:[97.850]\nepoch:[2/20] cost:[0.058] test_accuracy:[98.550]\nepoch:[3/20] cost:[0.044] test_accuracy:[98.570]\nepoch:[4/20] cost:[0.037] test_accuracy:[98.800]\nepoch:[5/20] cost:[0.031] test_accuracy:[98.770]\nepoch:[6/20] cost:[0.027] test_accuracy:[98.820]\nepoch:[7/20] cost:[0.023] test_accuracy:[98.860]\nepoch:[8/20] cost:[0.021] test_accuracy:[98.690]\nepoch:[9/20] cost:[0.020] test_accuracy:[98.780]\nepoch:[10/20] cost:[0.019] test_accuracy:[98.880]\nepoch:[11/20] cost:[0.017] test_accuracy:[98.830]\nepoch:[12/20] cost:[0.014] test_accuracy:[98.800]\nepoch:[13/20] cost:[0.013] test_accuracy:[98.930]\nepoch:[14/20] cost:[0.012] test_accuracy:[98.950]\nepoch:[15/20] cost:[0.014] test_accuracy:[98.920]\nepoch:[16/20] cost:[0.014] test_accuracy:[98.950]\nepoch:[17/20] cost:[0.012] test_accuracy:[98.880]\nepoch:[18/20] cost:[0.012] test_accuracy:[98.830]\nepoch:[19/20] cost:[0.012] test_accuracy:[98.920]\nepoch:[20/20] cost:[0.010] test_accuracy:[98.930]\nDone.\n"
    }
   ],
   "source": [
    "max_epoch,batch_size,print_every = 20,128,1\n",
    "max_iter = np.ceil(n_train/batch_size).astype(np.int) # number of iterations\n",
    "for epoch in range(max_epoch):\n",
    "    p_idx = np.random.permutation(n_train)\n",
    "    cost_val_sum,cnt = 0,0\n",
    "    for it in range(max_iter):\n",
    "        b_idx = p_idx[batch_size*(it):batch_size*(it+1)]\n",
    "        x_batch,y_batch = x_train[b_idx].to(device), y_train[b_idx].to(device)\n",
    "        cost_val = C.update(x_batch=x_batch,y_batch=y_batch)\n",
    "        cost_val_sum += cost_val*len(b_idx)\n",
    "        cnt += len(b_idx)\n",
    "    cost_val_avg = cost_val_sum / cnt\n",
    "    if ((epoch%print_every)==0) or (epoch==(max_epoch-1)):\n",
    "        accr_val = C.get_accr(x_test, y_test, batch_size)\n",
    "        print (\"epoch:[%d/%d] cost:[%.3f] test_accuracy:[%.3f]\"%\n",
    "               (epoch+1,max_epoch,cost_val_avg,accr_val))\n",
    "print (\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}